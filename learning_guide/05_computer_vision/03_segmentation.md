# 5.3 ì„¸ê·¸ë©˜í…Œì´ì…˜ í™œìš©

YOLO ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ì‚¬ìš©í•œ í”½ì…€ ë‹¨ìœ„ ê°ì²´ ë¶„í•  ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤.

## 1. ì„¸ê·¸ë©˜í…Œì´ì…˜ì´ë€?

### 1.1 ë°”ìš´ë”© ë°•ìŠ¤ vs ì„¸ê·¸ë©˜í…Œì´ì…˜

**ë°”ìš´ë”© ë°•ìŠ¤ (Detection)**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ    â”‚  ì‚¬ê³¼ ì˜ì—­ + ë°°ê²½ í¬í•¨
â”‚         â”‚  ì§ì‚¬ê°í˜• ì˜ì—­
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ì„¸ê·¸ë©˜í…Œì´ì…˜ (Segmentation)**
```
   ğŸ      í”½ì…€ ë‹¨ìœ„ ì •í™•í•œ ê²½ê³„
  ğŸğŸ     ë§ˆìŠ¤í¬ í˜•íƒœ
   ğŸ      ë°°ê²½ ì œì™¸
```

### 1.2 ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¥ì 

- **ì •í™•í•œ ê²½ê³„**: í”½ì…€ ë‹¨ìœ„ ê°ì²´ ì˜ì—­
- **ë©´ì  ê³„ì‚°**: ì‹¤ì œ ê°ì²´ í¬ê¸° ì¸¡ì •
- **ê²¹ì¹¨ ì²˜ë¦¬**: ì—¬ëŸ¬ ê°ì²´ êµ¬ë¶„
- **ì •ë°€ ì œì–´**: ë¡œë´‡ ê·¸ë¦¬í•‘ ìµœì í™”

---

## 2. YOLOv8 ì„¸ê·¸ë©˜í…Œì´ì…˜

### 2.1 ëª¨ë¸ ì„ íƒ

| ëª¨ë¸ | í¬ê¸° | mAP-box | mAP-seg | ì†ë„ |
|------|------|---------|---------|------|
| yolov8n-seg.pt | 6.7MB | 36.7 | 30.5 | ê°€ì¥ ë¹ ë¦„ |
| yolov8s-seg.pt | 21.5MB | 44.6 | 36.8 | ë¹ ë¦„ |
| yolov8m-seg.pt | 49.9MB | 49.9 | 40.8 | ì¤‘ê°„ |
| yolov8l-seg.pt | 83.6MB | 52.3 | 42.6 | ëŠë¦¼ |
| yolov8x-seg.pt | 130.5MB | 53.4 | 43.4 | ê°€ì¥ ëŠë¦¼ |

**XLeRobot ê¶Œì¥**: `yolov8n-seg.pt` (ì‹¤ì‹œê°„) ë˜ëŠ” `yolov8s-seg.pt` (ê· í˜•)

### 2.2 ê¸°ë³¸ ì‚¬ìš©ë²•

```python
from ultralytics import YOLO
import cv2

# ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ
model = YOLO('yolov8n-seg.pt')

# ì´ë¯¸ì§€ ë¡œë“œ
image = cv2.imread('input.jpg')

# ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰
results = model(image)

# ê²°ê³¼ ì‹œê°í™” (ë§ˆìŠ¤í¬ í¬í•¨)
annotated = results[0].plot()
cv2.imshow('Segmentation', annotated)
cv2.waitKey(0)
```

---

## 3. ë§ˆìŠ¤í¬ ë°ì´í„° ì¶”ì¶œ

### 3.1 ë§ˆìŠ¤í¬ ì •ë³´

```python
results = model(image)

# ì²« ë²ˆì§¸ ê²°ê³¼
r = results[0]

# ë§ˆìŠ¤í¬ í™•ì¸
if r.masks is not None:
    print(f"Total objects: {len(r.masks)}")
    
    for i, mask in enumerate(r.masks):
        # ë§ˆìŠ¤í¬ ë°°ì—´ (HÃ—W)
        mask_array = mask.data[0].cpu().numpy()
        
        # í´ë˜ìŠ¤
        class_id = int(r.boxes[i].cls[0])
        class_name = model.names[class_id]
        
        print(f"Object {i}: {class_name}")
        print(f"Mask shape: {mask_array.shape}")
```

### 3.2 ë°”ì´ë„ˆë¦¬ ë§ˆìŠ¤í¬ ìƒì„±

```python
import numpy as np

def get_binary_mask(results, index=0):
    """íŠ¹ì • ê°ì²´ì˜ ë°”ì´ë„ˆë¦¬ ë§ˆìŠ¤í¬ ë°˜í™˜"""
    if results[0].masks is None:
        return None
    
    # ë§ˆìŠ¤í¬ ë°ì´í„° (0~1 ë²”ìœ„)
    mask = results[0].masks[index].data[0].cpu().numpy()
    
    # ë°”ì´ë„ˆë¦¬ ë³€í™˜ (0 or 255)
    binary_mask = (mask > 0.5).astype(np.uint8) * 255
    
    return binary_mask

# ì‚¬ìš©
results = model(image)
mask = get_binary_mask(results, index=0)

if mask is not None:
    cv2.imshow('Binary Mask', mask)
    cv2.waitKey(0)
```

---

## 4. ë§ˆìŠ¤í¬ í™œìš©

### 4.1 ê°ì²´ ì˜ì—­ ì¶”ì¶œ

```python
def extract_object(image, mask):
    """ë§ˆìŠ¤í¬ë¥¼ ì‚¬ìš©í•´ ê°ì²´ë§Œ ì¶”ì¶œ"""
    # 3ì±„ë„ë¡œ í™•ì¥
    mask_3ch = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
    
    # ë§ˆìŠ¤í¬ ì ìš© (ë°°ê²½ ì œê±°)
    masked_image = cv2.bitwise_and(image, mask_3ch)
    
    return masked_image

# ì‚¬ìš©
results = model(image)
mask = get_binary_mask(results, 0)
object_only = extract_object(image, mask)

cv2.imshow('Extracted Object', object_only)
```

### 4.2 ë©´ì  ê³„ì‚°

```python
def calculate_area(mask, pixel_to_cm2=0.01):
    """ë§ˆìŠ¤í¬ ë©´ì  ê³„ì‚° (cmÂ²)"""
    # í”½ì…€ ê°œìˆ˜
    pixel_count = np.sum(mask > 0)
    
    # ì‹¤ì œ ë©´ì  (ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš”)
    area_cm2 = pixel_count * pixel_to_cm2
    
    return area_cm2

# ì‚¬ìš©
results = model(image)
for i, mask_data in enumerate(results[0].masks):
    mask = (mask_data.data[0].cpu().numpy() > 0.5).astype(np.uint8) * 255
    area = calculate_area(mask)
    
    class_name = model.names[int(results[0].boxes[i].cls[0])]
    print(f"{class_name}: {area:.1f} cmÂ²")
```

### 4.3 ì¤‘ì‹¬ì  ì°¾ê¸°

```python
def find_mask_center(mask):
    """ë§ˆìŠ¤í¬ì˜ ë¬´ê²Œì¤‘ì‹¬ (centroid)"""
    # ëª¨ë©˜íŠ¸ ê³„ì‚°
    M = cv2.moments(mask)
    
    if M['m00'] == 0:
        return None
    
    # ì¤‘ì‹¬ ì¢Œí‘œ
    cx = int(M['m10'] / M['m00'])
    cy = int(M['m01'] / M['m00'])
    
    return (cx, cy)

# ì‚¬ìš©
results = model(image)
mask = get_binary_mask(results, 0)
center = find_mask_center(mask)

if center is not None:
    cv2.circle(image, center, 5, (0, 255, 0), -1)
    print(f"Center: {center}")
```

---

## 5. ì—¬ëŸ¬ ê°ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜

### 5.1 í´ë˜ìŠ¤ë³„ ë§ˆìŠ¤í¬

```python
def get_masks_by_class(results, target_class='person'):
    """íŠ¹ì • í´ë˜ìŠ¤ì˜ ëª¨ë“  ë§ˆìŠ¤í¬ ë°˜í™˜"""
    if results[0].masks is None:
        return []
    
    masks = []
    
    for i, box in enumerate(results[0].boxes):
        class_id = int(box.cls[0])
        class_name = results[0].names[class_id]
        
        if class_name == target_class:
            mask = results[0].masks[i].data[0].cpu().numpy()
            binary_mask = (mask > 0.5).astype(np.uint8) * 255
            masks.append(binary_mask)
    
    return masks

# ì‚¬ìš©
results = model(image)
person_masks = get_masks_by_class(results, 'person')

print(f"Found {len(person_masks)} person(s)")
```

### 5.2 ë§ˆìŠ¤í¬ í•©ì„±

```python
def combine_masks(masks):
    """ì—¬ëŸ¬ ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨"""
    if len(masks) == 0:
        return None
    
    # ì²« ë²ˆì§¸ ë§ˆìŠ¤í¬ë¡œ ì´ˆê¸°í™”
    combined = masks[0].copy()
    
    # OR ì—°ì‚°ìœ¼ë¡œ í•©ì¹¨
    for mask in masks[1:]:
        combined = cv2.bitwise_or(combined, mask)
    
    return combined

# ì‚¬ìš©
all_masks = get_masks_by_class(results, 'person')
combined = combine_masks(all_masks)

if combined is not None:
    cv2.imshow('Combined Mask', combined)
```

---

## 6. ì„¸ê·¸ë©˜í…Œì´ì…˜ + ì¶”ì 

### 6.1 ë§ˆìŠ¤í¬ì™€ ì¶”ì  ID

```python
from ultralytics import YOLO
import cv2

model = YOLO('yolov8n-seg.pt')
cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break
    
    # ì„¸ê·¸ë©˜í…Œì´ì…˜ + ì¶”ì 
    results = model.track(frame, persist=True)
    
    if results[0].masks is not None:
        for i, (box, mask) in enumerate(zip(results[0].boxes, 
                                            results[0].masks)):
            # ì¶”ì  ID
            if box.id is not None:
                track_id = int(box.id[0])
            else:
                track_id = -1
            
            # ë§ˆìŠ¤í¬ ì¶”ì¶œ
            mask_arr = (mask.data[0].cpu().numpy() > 0.5).astype(np.uint8) * 255
            
            # ì¤‘ì‹¬ì 
            center = find_mask_center(mask_arr)
            
            if center is not None:
                # ID í‘œì‹œ
                cv2.putText(frame, f"ID: {track_id}", center,
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
    
    annotated = results[0].plot()
    cv2.imshow('Seg + Track', annotated)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

---

## 7. ë¡œë´‡ ì‘ìš©

### 7.1 ê·¸ë¦¬í•‘ í¬ì¸íŠ¸ ì°¾ê¸°

```python
def find_grasp_point(mask):
    """ë§ˆìŠ¤í¬ì—ì„œ ìµœì  ê·¸ë¦¬í•‘ ì§€ì  ì°¾ê¸°"""
    # ìœ¤ê³½ì„  ì°¾ê¸°
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, 
                                   cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        return None
    
    # ê°€ì¥ í° ìœ¤ê³½ì„ 
    largest = max(contours, key=cv2.contourArea)
    
    # ìµœì†Œ ì™¸ì ‘ ì›
    (cx, cy), radius = cv2.minEnclosingCircle(largest)
    
    return (int(cx), int(cy)), int(radius)

# ì‚¬ìš©
results = model(image)
mask = get_binary_mask(results, 0)

grasp_info = find_grasp_point(mask)
if grasp_info is not None:
    center, radius = grasp_info
    
    # ì‹œê°í™”
    cv2.circle(image, center, radius, (0, 255, 0), 2)
    cv2.circle(image, center, 5, (0, 0, 255), -1)
    
    print(f"Grasp at: {center}, size: {radius}px")
```

### 7.2 ê°ì²´ ë°©í–¥ ì¶”ì •

```python
def estimate_orientation(mask):
    """ê°ì²´ ë°©í–¥ (ê°ë„) ì¶”ì •"""
    # ìœ¤ê³½ì„ 
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, 
                                   cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        return None
    
    largest = max(contours, key=cv2.contourArea)
    
    # ìµœì†Œ ì™¸ì ‘ ì‚¬ê°í˜•
    rect = cv2.minAreaRect(largest)
    angle = rect[2]
    
    # ë°•ìŠ¤ ì¢Œí‘œ
    box = cv2.boxPoints(rect)
    box = np.int0(box)
    
    return angle, box

# ì‚¬ìš©
results = model(image)
mask = get_binary_mask(results, 0)

orientation = estimate_orientation(mask)
if orientation is not None:
    angle, box = orientation
    
    # ê·¸ë¦¬ê¸°
    cv2.drawContours(image, [box], 0, (0, 255, 0), 2)
    print(f"Orientation: {angle:.1f}Â°")
```

---

## 8. ì‹¤ì „ ì˜ˆì œ

### 8.1 ì»µ ê°ì§€ ë° ê·¸ë¦¬í•‘

```python
from ultralytics import YOLO
import cv2
import numpy as np

model = YOLO('yolov8n-seg.pt')

def find_cup_grasp(image):
    """ì»µ ì°¾ì•„ì„œ ê·¸ë¦¬í•‘ í¬ì¸íŠ¸ ë°˜í™˜"""
    results = model(image, classes=[41])  # cup = 41
    
    if results[0].masks is None or len(results[0].masks) == 0:
        return None
    
    # ì²« ë²ˆì§¸ ì»µ
    mask = (results[0].masks[0].data[0].cpu().numpy() > 0.5).astype(np.uint8) * 255
    
    # ê·¸ë¦¬í•‘ í¬ì¸íŠ¸
    grasp = find_grasp_point(mask)
    
    if grasp is not None:
        center, radius = grasp
        return {
            'position': center,
            'size': radius,
            'mask': mask
        }
    
    return None

# ì‹¤ì‹œê°„ ê°ì§€
cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    
    cup_info = find_cup_grasp(frame)
    
    if cup_info is not None:
        # ê·¸ë¦¬í•‘ í¬ì¸íŠ¸ í‘œì‹œ
        cv2.circle(frame, cup_info['position'], 
                  cup_info['size'], (0, 255, 0), 2)
        cv2.circle(frame, cup_info['position'], 
                  5, (0, 0, 255), -1)
        
        # ì¢Œí‘œ ì¶œë ¥
        x, y = cup_info['position']
        cv2.putText(frame, f"Grasp: ({x}, {y})", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    
    cv2.imshow('Cup Detection', frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

---

## 9. ì„±ëŠ¥ ìµœì í™”

### 9.1 ë§ˆìŠ¤í¬ í•´ìƒë„ ì¡°ì •

```python
# ë‚®ì€ í•´ìƒë„ë¡œ ì¶”ë¡  (ë¹ ë¦„)
results = model(image, imgsz=320)  # ê¸°ë³¸ 640 â†’ 320

# ë§ˆìŠ¤í¬ ì›ë³¸ í¬ê¸°ë¡œ ë³µì›
for mask in results[0].masks:
    # ìë™ìœ¼ë¡œ ì›ë³¸ í¬ê¸°ì— ë§ì¶°ì§
    mask_array = mask.data[0].cpu().numpy()
```

### 9.2 GPU ì‚¬ìš©

```python
import torch

# GPU í™•ì¸
if torch.cuda.is_available():
    model = YOLO('yolov8n-seg.pt').to('cuda')
    print("Using GPU")
else:
    model = YOLO('yolov8n-seg.pt')
    print("Using CPU")

# ì¶”ë¡ 
results = model(image)
```

---

## 10. ì»¤ìŠ¤í…€ ì„¸ê·¸ë©˜í…Œì´ì…˜ í•™ìŠµ

### 10.1 ë°ì´í„°ì…‹ ì¤€ë¹„

```yaml
# dataset.yaml
path: /path/to/dataset
train: images/train
val: images/val

nc: 2
names: ['cup', 'bottle']
```

**í´ë” êµ¬ì¡°:**
```
dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ val/
â””â”€â”€ labels/
    â”œâ”€â”€ train/
    â”‚   â””â”€â”€ img001.txt  # ì„¸ê·¸ë©˜í…Œì´ì…˜ í¬ë§·
    â””â”€â”€ val/
```

**ë¼ë²¨ í˜•ì‹ (YOLO seg):**
```
class_id x1 y1 x2 y2 x3 y3 ... (polygon points, normalized)
0 0.1 0.2 0.3 0.2 0.3 0.4 0.1 0.4
```

### 10.2 í•™ìŠµ

```python
from ultralytics import YOLO

model = YOLO('yolov8n-seg.pt')

results = model.train(
    data='dataset.yaml',
    epochs=100,
    imgsz=640,
    batch=8
)
```

---

## 11. ë””ë²„ê¹…

### 11.1 ë§ˆìŠ¤í¬ ì‹œê°í™”

```python
def visualize_mask(image, mask, alpha=0.5):
    """ë§ˆìŠ¤í¬ë¥¼ ë°˜íˆ¬ëª… ì˜¤ë²„ë ˆì´"""
    # ì»¬ëŸ¬ ë§ˆìŠ¤í¬ (ë…¹ìƒ‰)
    colored_mask = np.zeros_like(image)
    colored_mask[mask > 0] = [0, 255, 0]
    
    # ë¸”ë Œë”©
    overlay = cv2.addWeighted(image, 1-alpha, colored_mask, alpha, 0)
    
    return overlay

# ì‚¬ìš©
results = model(image)
mask = get_binary_mask(results, 0)
vis = visualize_mask(image, mask, alpha=0.3)

cv2.imshow('Mask Overlay', vis)
```

### 11.2 ë¬¸ì œ í•´ê²°

| ì¦ìƒ | ì›ì¸ | í•´ê²° |
|------|------|------|
| ë§ˆìŠ¤í¬ ì—†ìŒ | detection ëª¨ë¸ ì‚¬ìš© | `-seg.pt` ëª¨ë¸ ì‚¬ìš© |
| ê²½ê³„ ë¶€ì •í™• | ë‚®ì€ conf | `conf=0.6` ìƒí–¥ |
| ëŠë¦° ì†ë„ | í° ì´ë¯¸ì§€ | `imgsz=320` ì¶•ì†Œ |
| ë©”ëª¨ë¦¬ ë¶€ì¡± | batch ê³¼ë‹¤ | `batch=4` ì¶•ì†Œ |

---

## 12. ì°¸ê³  ìë£Œ

- [YOLOv8 Segmentation](https://docs.ultralytics.com/tasks/segment/)
- [Instance Segmentation](https://paperswithcode.com/task/instance-segmentation)
- [OpenCV Contours](https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html)

---

[â† 5.2 ê°ì²´ ì¶”ì ](https://github.com/dinnerandcoffee/xlerobot-learning-guide/blob/main/learning_guide/05_computer_vision/02_object_tracking.md) | [ë‹¤ìŒ: 5.4 ë¹„ì „ ê¸°ë°˜ ë¡œë´‡ ì œì–´ â†’](https://github.com/dinnerandcoffee/xlerobot-learning-guide/blob/main/learning_guide/05_computer_vision/04_vision_control.md)
